---
title: 14. 性能优化
---

## 1. 内存优化

### 1.1 内存分配
```go
// 预分配切片
slice := make([]int, 0, 1000)
for i := 0; i < 1000; i++ {
    slice = append(slice, i)
}

// 复用对象
var pool = sync.Pool{
    New: func() interface{} {
        return make([]byte, 1024)
    },
}

func getBuffer() []byte {
    return pool.Get().([]byte)
}

func putBuffer(buf []byte) {
    pool.Put(buf)
}
```

### 1.2 垃圾回收
```go
// 减少内存分配
func process(data []byte) {
    // 复用缓冲区
    buf := make([]byte, 1024)
    for i := 0; i < len(data); i += 1024 {
        copy(buf, data[i:i+1024])
        // 处理数据
    }
}

// 控制GC
debug.SetGCPercent(100) // 设置GC触发阈值
runtime.GC() // 手动触发GC
```

### 1.3 内存分析
```go
// 内存分析
import "runtime/pprof"

func main() {
    f, _ := os.Create("mem.prof")
    pprof.WriteHeapProfile(f)
    f.Close()
}

// 使用 pprof 工具
go tool pprof -http=:8080 mem.prof
```

## 2. CPU 优化

### 2.1 算法优化
```go
// 使用更高效的算法
func findMax(nums []int) int {
    max := nums[0]
    for _, num := range nums[1:] {
        if num > max {
            max = num
        }
    }
    return max
}

// 避免重复计算
func process(data []int) {
    sum := 0
    for _, num := range data {
        sum += num
    }
    avg := sum / len(data)
    // 使用 avg
}
```

### 2.2 并发优化
```go
// 并行处理
func processParallel(data []int) {
    var wg sync.WaitGroup
    chunkSize := len(data) / runtime.NumCPU()
    
    for i := 0; i < len(data); i += chunkSize {
        wg.Add(1)
        go func(start int) {
            defer wg.Done()
            end := start + chunkSize
            if end > len(data) {
                end = len(data)
            }
            processChunk(data[start:end])
        }(i)
    }
    wg.Wait()
}
```

### 2.3 CPU 分析
```go
// CPU 分析
import "runtime/pprof"

func main() {
    f, _ := os.Create("cpu.prof")
    pprof.StartCPUProfile(f)
    defer pprof.StopCPUProfile()
    
    // 执行需要分析的代码
}

// 使用 pprof 工具
go tool pprof -http=:8080 cpu.prof
```

## 3. I/O 优化

### 3.1 文件 I/O
```go
// 使用缓冲
func readFile(filename string) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    reader := bufio.NewReader(file)
    for {
        line, err := reader.ReadString('\n')
        if err != nil {
            break
        }
        // 处理行
    }
    return nil
}

// 批量写入
func writeBatch(data []string) error {
    file, err := os.Create("output.txt")
    if err != nil {
        return err
    }
    defer file.Close()
    
    writer := bufio.NewWriter(file)
    for _, line := range data {
        writer.WriteString(line)
    }
    return writer.Flush()
}
```

### 3.2 网络 I/O
```go
// 连接池
var client = &http.Client{
    Transport: &http.Transport{
        MaxIdleConns:        100,
        MaxIdleConnsPerHost: 100,
        IdleConnTimeout:     90 * time.Second,
    },
}

// 批量请求
func batchRequests(urls []string) {
    var wg sync.WaitGroup
    sem := make(chan struct{}, 10) // 限制并发数
    
    for _, url := range urls {
        wg.Add(1)
        go func(url string) {
            defer wg.Done()
            sem <- struct{}{}
            defer func() { <-sem }()
            
            resp, err := client.Get(url)
            if err != nil {
                return
            }
            defer resp.Body.Close()
            // 处理响应
        }(url)
    }
    wg.Wait()
}
```

### 3.3 I/O 分析
```go
// I/O 分析
import "net/http/pprof"

func main() {
    go func() {
        log.Println(http.ListenAndServe("localhost:6060", nil))
    }()
    
    // 执行需要分析的代码
}

// 使用 pprof 工具
go tool pprof -http=:8080 http://localhost:6060/debug/pprof/block
```

## 4. 并发优化

### 4.1 Goroutine 优化
```go
// 控制 Goroutine 数量
func processTasks(tasks []Task) {
    var wg sync.WaitGroup
    sem := make(chan struct{}, runtime.NumCPU()*2)
    
    for _, task := range tasks {
        wg.Add(1)
        go func(t Task) {
            defer wg.Done()
            sem <- struct{}{}
            defer func() { <-sem }()
            
            processTask(t)
        }(task)
    }
    wg.Wait()
}

// Goroutine 池
type Pool struct {
    work chan func()
    sem  chan struct{}
}

func NewPool(size int) *Pool {
    return &Pool{
        work: make(chan func()),
        sem:  make(chan struct{}, size),
    }
}

func (p *Pool) Submit(task func()) {
    select {
    case p.work <- task:
    case p.sem <- struct{}{}:
        go p.worker(task)
    }
}
```

### 4.2 锁优化
```go
// 减少锁竞争
type Counter struct {
    mu    sync.Mutex
    count int
}

func (c *Counter) Increment() {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.count++
}

// 使用读写锁
type Cache struct {
    mu    sync.RWMutex
    data  map[string]interface{}
}

func (c *Cache) Get(key string) interface{} {
    c.mu.RLock()
    defer c.mu.RUnlock()
    return c.data[key]
}

func (c *Cache) Set(key string, value interface{}) {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.data[key] = value
}
```

### 4.3 并发分析
```go
// 并发分析
import "net/http/pprof"

func main() {
    go func() {
        log.Println(http.ListenAndServe("localhost:6060", nil))
    }()
    
    // 执行需要分析的代码
}

// 使用 pprof 工具
go tool pprof -http=:8080 http://localhost:6060/debug/pprof/goroutine
```

## 5. 编译优化

### 5.1 编译选项
```go
// 编译优化
go build -gcflags="-m -m" main.go

// 内联优化
//go:noinline
func expensive() int {
    return 42
}

// 逃逸分析
func escape() *int {
    x := 42
    return &x // 逃逸到堆
}
```

### 5.2 链接优化
```go
// 链接优化
go build -ldflags="-s -w" main.go

// 剥离调试信息
go build -ldflags="-s" main.go

// 压缩二进制
go build -ldflags="-w" main.go
```

### 5.3 优化分析
```go
// 优化分析
go build -gcflags="-m" main.go

// 查看汇编
go tool compile -S main.go

// 查看优化
go tool compile -m main.go
```

## 最佳实践

1. **内存优化**
   - 预分配内存
   - 复用对象
   - 控制GC

2. **CPU 优化**
   - 选择高效算法
   - 避免重复计算
   - 利用并发

3. **I/O 优化**
   - 使用缓冲
   - 批量操作
   - 控制并发

4. **并发优化**
   - 控制 Goroutine 数量
   - 减少锁竞争
   - 使用连接池

5. **编译优化**
   - 使用优化选项
   - 控制内联
   - 分析逃逸 